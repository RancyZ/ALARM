{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34798a9c-d294-4803-bc88-abc91299c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# List of model names\n",
    "model_names = [\n",
    "    \"claude3.5sonnet\",\n",
    "    \"claude3.5\",\n",
    "    \"claude3.7\",\n",
    "    \"gpt4o-mini\",\n",
    "    \"gpt4o\"\n",
    "]\n",
    "\n",
    "# Function to remove control characters\n",
    "def clean_text(s):\n",
    "    return re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]\", \"\", s)\n",
    "\n",
    "# Function to extract updated_prediction from content\n",
    "def extract_prediction(content):\n",
    "    try:\n",
    "        if isinstance(content, list):\n",
    "            content = next((c for c in content if isinstance(c, str) and c.strip()), \"\")\n",
    "        if not isinstance(content, str) or not content.strip():\n",
    "            return \"\"\n",
    "        content_clean = clean_text(content)\n",
    "        match = re.search(r'\"updated_prediction\"\\s*:\\s*\"([^\"]*?)\"', content_clean, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n",
    "# Collect predictions for all models\n",
    "all_model_preds = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    file_path = f\"../../LLM_output_generation/rule10_{model_name}_1.json\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        llm_data = json.load(f)\n",
    "    \n",
    "    for filename, content in llm_data.items():\n",
    "        prediction = extract_prediction(content)\n",
    "        if filename not in all_model_preds:\n",
    "            all_model_preds[filename] = {\"video_name\": filename}\n",
    "        all_model_preds[filename][f\"{model_name}-anomaly\"] = prediction\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_all_preds = pd.DataFrame(list(all_model_preds.values()))\n",
    "\n",
    "# Save to Excel\n",
    "df_all_preds.to_excel(\"extracted_video_anomalies_all_models_updated_all.xlsx\", index=False)\n",
    "print(\"Saved to extracted_video_anomalies_all_models_updated_all.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d9537-9ea9-4ea3-868f-cb8c9b2d2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two Excel files\n",
    "df1 = pd.read_excel(\"../desc/embedded_only_video_anomalies.xlsx\")\n",
    "df2 = pd.read_excel(\"extracted_video_anomalies_all_models_updated_all.xlsx\")\n",
    "\n",
    "# Define model names\n",
    "models = [\"claude3.5sonnet\", \"claude3.5\", \"claude3.7\", \"gpt4o-mini\", \"gpt4o\"]\n",
    "\n",
    "# Rename df1 columns to have \"-anomaly\" suffix like df2\n",
    "df1 = df1.rename(columns={model: f\"{model}-anomaly\" for model in models})\n",
    "\n",
    "# Perform an outer merge to keep all video_name values from both dataframes\n",
    "merged_df = pd.merge(df1, df2, on=\"video_name\", suffixes=('_df1', '_df2'), how=\"outer\")\n",
    "\n",
    "# For each model, compare anomalies and assign 1 (match) or 0 (not match)\n",
    "for model in models:\n",
    "    col1 = f\"{model}-anomaly_df1\"\n",
    "    col2 = f\"{model}-anomaly_df2\"\n",
    "    match_col = f\"{model}_y\"\n",
    "    merged_df[match_col] = (\n",
    "        merged_df[col1].fillna(\"NA\") == merged_df[col2].fillna(\"NA\")\n",
    "    ).astype(int)\n",
    "\n",
    "# Keep only video_name and match columns\n",
    "output_cols = [\"video_name\"] + [f\"{model}_y\" for model in models]\n",
    "result_df = merged_df[output_cols]\n",
    "\n",
    "# Save to Excel\n",
    "result_df.to_excel(\"anomaly_label_comparison_y.xlsx\", index=False)\n",
    "print(\"✅ Match matrix saved as anomaly_match_matrix_full.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccd238-4164-4af2-9387-12d5fca32ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Load files\n",
    "    y_df = pd.read_excel('anomaly_label_comparison_y.xlsx')\n",
    "\n",
    "    #To obtain embedded_only_video_anomalies_reas_label.xlsx, we only need to keep columns regarding reasoning embedding and labels in embedded_only_video_anomalies.xlsx\n",
    "\n",
    "    features_df = pd.read_excel('embedded_only_video_anomalies_reas_label.xlsx')\n",
    "    rule_df = pd.read_excel('embedded_combined_handcraft_rule.xlsx')\n",
    "    train_videos_df = pd.read_excel(f'train_dataset_{suffix}.xlsx')\n",
    "    test_videos_df = pd.read_excel('../reas/test_dataset_reas.xlsx')\n",
    "    \n",
    "    # Rename 'test video' to 'video_name' in test dataset if needed\n",
    "    if 'test video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test video': 'video_name'}, inplace=True)\n",
    "    elif 'test_video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test_video': 'video_name'}, inplace=True)\n",
    "    \n",
    "    # Clean and parse rule embedding\n",
    "    rule_text_raw = rule_df['embedding'].iloc[0]\n",
    "    rule_text_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', rule_text_raw)\n",
    "    rule_embedding = np.array(eval(rule_text_clean))\n",
    "    \n",
    "    # Model list\n",
    "    model_list = [\"claude3.5sonnet\", \"claude3.5\", \"claude3.7\", \"gpt4o-mini\", \"gpt4o\"]\n",
    "    \n",
    "    # Training and test video names with .mp4 suffix\n",
    "    train_video_names = set(train_videos_df['video_name'].astype(str) + \".jpg\")\n",
    "    test_video_names = set(test_videos_df['video_name'].astype(str) + \".jpg\")\n",
    "    \n",
    "    # Store final results: video_name + 5 probabilities + average\n",
    "    prob_output = []\n",
    "    \n",
    "    # Initialize dict to store probabilities by model\n",
    "    prob_dict = {model: {} for model in model_list}\n",
    "    \n",
    "    # Loop over models\n",
    "    for model in model_list:\n",
    "        feature_list = []\n",
    "        y_list = []\n",
    "        video_name_list = []\n",
    "    \n",
    "        reas_emb_series = features_df[f\"{model}-reas_emb\"]\n",
    "        anomaly_series = features_df[f\"{model}-anomaly\"]\n",
    "        y_series = y_df[f\"{model}_y\"]\n",
    "        video_series = features_df['video_name']\n",
    "    \n",
    "        for emb_str, anom, label, vid in zip(reas_emb_series, anomaly_series, y_series, video_series):\n",
    "            if isinstance(emb_str, str):\n",
    "                emb_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', emb_str)\n",
    "                emb = np.array(eval(emb_clean))\n",
    "    \n",
    "                feature = np.concatenate([emb, [anom], rule_embedding])\n",
    "                feature_list.append(feature)\n",
    "                y_list.append(label)\n",
    "                video_name_list.append(vid)\n",
    "    \n",
    "        X = np.vstack(feature_list)\n",
    "        y = np.array(y_list)\n",
    "        video_names = np.array(video_name_list)\n",
    "    \n",
    "        # Split into train/test based on train/test datasets\n",
    "        train_idx = np.isin(video_names, list(train_video_names))\n",
    "        test_idx = np.isin(video_names, list(test_video_names))\n",
    "    \n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, video_test = X[test_idx], video_names[test_idx]\n",
    "    \n",
    "        model_lr = LogisticRegression(max_iter=1000)\n",
    "        model_lr.fit(X_train, y_train)\n",
    "    \n",
    "        # Predict probabilities on test set (probability of class 1)\n",
    "        probs = model_lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "        # Store probabilities by video name\n",
    "        for vid, prob in zip(video_test, probs):\n",
    "            prob_dict[model][vid] = prob\n",
    "    \n",
    "    # Collect all test video names (union from all models' outputs)\n",
    "    all_video_names = set()\n",
    "    for model_probs in prob_dict.values():\n",
    "        all_video_names.update(model_probs.keys())\n",
    "    \n",
    "    # Build final output\n",
    "    for vid in sorted(all_video_names):\n",
    "        row = {'video_name': vid}\n",
    "        prob_values = []\n",
    "        for model in model_list:\n",
    "            prob = prob_dict[model].get(vid, np.nan)\n",
    "            row[f\"{model}_prob\"] = prob\n",
    "            prob_values.append(prob)\n",
    "        row['average_prob'] = np.nanmean(prob_values)\n",
    "        prob_output.append(row)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_df = pd.DataFrame(prob_output)\n",
    "    output_df.to_excel(f\"model_prediction_probabilities_{suffix}.xlsx\", index=False)\n",
    "    \n",
    "    print(\"✅ Probability file saved as: model_prediction_probabilities.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6029b85-0617-4b3a-a9d1-6a4a7e0856b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Load files\n",
    "    y_df = pd.read_excel('anomaly_label_comparison_y.xlsx')\n",
    "    features_df = pd.read_excel('embedded_only_video_anomalies_reas_label.xlsx')\n",
    "    rule_df = pd.read_excel('embedded_combined_handcraft_rule.xlsx')\n",
    "    train_videos_df = pd.read_excel(f'train_dataset_{suffix}.xlsx')\n",
    "    # test_videos_df = pd.read_excel('test_dataset_reas.xlsx')\n",
    "\n",
    "    test_videos_df = pd.read_excel(f'train_dataset_{suffix}.xlsx')\n",
    "    \n",
    "    # Rename 'test video' to 'video_name' in test dataset if needed\n",
    "    if 'test video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test video': 'video_name'}, inplace=True)\n",
    "    elif 'test_video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test_video': 'video_name'}, inplace=True)\n",
    "    \n",
    "    # Clean and parse rule embedding\n",
    "    rule_text_raw = rule_df['embedding'].iloc[0]\n",
    "    rule_text_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', rule_text_raw)\n",
    "    rule_embedding = np.array(eval(rule_text_clean))\n",
    "    \n",
    "    # Model list\n",
    "    model_list = [\"claude3.5sonnet\", \"claude3.5\", \"claude3.7\", \"gpt4o-mini\", \"gpt4o\"]\n",
    "    \n",
    "    # Training and test video names with .mp4 suffix\n",
    "    train_video_names = set(train_videos_df['video_name'].astype(str) + \".jpg\")\n",
    "    test_video_names = set(test_videos_df['video_name'].astype(str) + \".jpg\")\n",
    "    \n",
    "    # Store final results: video_name + 5 probabilities + average\n",
    "    prob_output = []\n",
    "    \n",
    "    # Initialize dict to store probabilities by model\n",
    "    prob_dict = {model: {} for model in model_list}\n",
    "    \n",
    "    # Loop over models\n",
    "    for model in model_list:\n",
    "        feature_list = []\n",
    "        y_list = []\n",
    "        video_name_list = []\n",
    "    \n",
    "        reas_emb_series = features_df[f\"{model}-reas_emb\"]\n",
    "        anomaly_series = features_df[f\"{model}-anomaly\"]\n",
    "        y_series = y_df[f\"{model}_y\"]\n",
    "        video_series = features_df['video_name']\n",
    "    \n",
    "        for emb_str, anom, label, vid in zip(reas_emb_series, anomaly_series, y_series, video_series):\n",
    "            if isinstance(emb_str, str):\n",
    "                emb_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', emb_str)\n",
    "                emb = np.array(eval(emb_clean))\n",
    "    \n",
    "                feature = np.concatenate([emb, [anom], rule_embedding])\n",
    "                feature_list.append(feature)\n",
    "                y_list.append(label)\n",
    "                video_name_list.append(vid)\n",
    "    \n",
    "        X = np.vstack(feature_list)\n",
    "        y = np.array(y_list)\n",
    "        video_names = np.array(video_name_list)\n",
    "    \n",
    "        # Split into train/test based on train/test datasets\n",
    "        train_idx = np.isin(video_names, list(train_video_names))\n",
    "        test_idx = np.isin(video_names, list(test_video_names))\n",
    "    \n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, video_test = X[test_idx], video_names[test_idx]\n",
    "    \n",
    "        model_lr = LogisticRegression(max_iter=1000)\n",
    "        model_lr.fit(X_train, y_train)\n",
    "    \n",
    "        # Predict probabilities on test set (probability of class 1)\n",
    "        probs = model_lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "        # Store probabilities by video name\n",
    "        for vid, prob in zip(video_test, probs):\n",
    "            prob_dict[model][vid] = prob\n",
    "    \n",
    "    # Collect all test video names (union from all models' outputs)\n",
    "    all_video_names = set()\n",
    "    for model_probs in prob_dict.values():\n",
    "        all_video_names.update(model_probs.keys())\n",
    "    \n",
    "    # Build final output\n",
    "    for vid in sorted(all_video_names):\n",
    "        row = {'video_name': vid}\n",
    "        prob_values = []\n",
    "        for model in model_list:\n",
    "            prob = prob_dict[model].get(vid, np.nan)\n",
    "            row[f\"{model}_prob\"] = prob\n",
    "            prob_values.append(prob)\n",
    "        row['average_prob'] = np.nanmean(prob_values)\n",
    "        prob_output.append(row)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_df = pd.DataFrame(prob_output)\n",
    "    output_df.to_excel(f\"model_prediction_probabilities_{suffix}_train.xlsx\", index=False)\n",
    "    \n",
    "    print(\"✅ Probability file saved as: model_prediction_probabilities.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87a9df-29c8-47fa-9238-28440a43c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    \n",
    "    prob_df = pd.read_excel(f'model_prediction_probabilities_{suffix}.xlsx')\n",
    "    \n",
    "    video_names = prob_df['video_name'].astype(str).values\n",
    "    uncertainty_scores = prob_df['average_prob']\n",
    "    \n",
    "    #uncertainty_scores = np.array(average_prob)  # Convert to NumPy array\n",
    "    \n",
    "    P_set = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    \n",
    "    for P in P_set:\n",
    "        tau = np.percentile(uncertainty_scores, 100 - P)\n",
    "        mask_low = uncertainty_scores <= tau\n",
    "        S_low_videos = video_names[mask_low]\n",
    "    \n",
    "        out_df = pd.DataFrame({\n",
    "            \"video_name\":  S_low_videos,\n",
    "            \"uncertainty\": uncertainty_scores[mask_low]\n",
    "        })\n",
    "        out_df.to_excel(f\"low list/S_low_videos_{P}_{suffix}_ref.xlsx\", index=False)\n",
    "        \n",
    "        print(f\"Threshold τ = {tau:.4f}\")\n",
    "        print(f\"Kept {len(S_low_videos)}/{len(video_names)} videos in S_low.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f45aa-aefa-4612-b295-bb5ba5307308",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    \n",
    "    prob_df = pd.read_excel(f'model_prediction_probabilities_{suffix}_train.xlsx')\n",
    "    \n",
    "    video_names = prob_df['video_name'].astype(str).values\n",
    "    uncertainty_scores = prob_df['average_prob']\n",
    "    \n",
    "    #uncertainty_scores = np.array(average_prob)  # Convert to NumPy array\n",
    "    \n",
    "    P_set = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    \n",
    "    for P in P_set:\n",
    "        tau = np.percentile(uncertainty_scores, 100 - P)\n",
    "        mask_low = uncertainty_scores <= tau\n",
    "        S_low_videos = video_names[mask_low]\n",
    "    \n",
    "        out_df = pd.DataFrame({\n",
    "            \"video_name\":  S_low_videos,\n",
    "            \"uncertainty\": uncertainty_scores[mask_low]\n",
    "        })\n",
    "        out_df.to_excel(f\"low list/S_low_videos_{P}_{suffix}_ref_train.xlsx\", index=False)\n",
    "        \n",
    "        print(f\"Threshold τ = {tau:.4f}\")\n",
    "        print(f\"Kept {len(S_low_videos)}/{len(video_names)} videos in S_low.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de7acb-314a-4d31-89c4-9e5b6baa1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"claude3.5sonnet\",\n",
    "    \"claude3.5\",\n",
    "    \"claude3.7\",\n",
    "    \"gpt4o-mini\",\n",
    "    \"gpt4o\"\n",
    "]\n",
    "# P values representing percent of videos excluded as high-uncertainty\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "    \n",
    "    # Store results for each P\n",
    "    all_results = []\n",
    "    \n",
    "    for P in P_set:\n",
    "        \n",
    "        try:\n",
    "            low = pd.read_excel(f'low list/S_low_videos_{P}_{suffix}_ref.xlsx')\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load S_low_videos_{P}_trace.xlsx: {e}\")\n",
    "            continue\n",
    "        \n",
    "        low_list = low['video_name'].str.replace('.jpg', '', regex=False)\n",
    "        \n",
    "        # Store predictions per model\n",
    "        model_preds = {}\n",
    "        \n",
    "        for model in model_names:\n",
    "            try:\n",
    "                df = pd.read_csv(f'../model_predictions/vad_results_{model}.csv')\n",
    "                df['Video Name'] = df['Video Name'].str.replace('.jpg', '', regex=False)\n",
    "                df = df[df['Video Name'].isin(low_list)]\n",
    "                model_preds[model] = df[['Video Name', 'Predicted Label']].set_index('Video Name')\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Failed to process {model}: {e}\")\n",
    "        \n",
    "        # Merge all predictions\n",
    "        merged = pd.DataFrame(index=low_list)\n",
    "        for model in model_names:\n",
    "            merged[model] = model_preds.get(model, pd.DataFrame()).reindex(low_list)['Predicted Label']\n",
    "        \n",
    "        # Drop rows with missing predictions\n",
    "        merged = merged.dropna()\n",
    "        \n",
    "        if merged.empty:\n",
    "            print(f\"[Warning] No valid data for P={P}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Load ground truth from claude-3-5-sonnet\n",
    "        gt_df = pd.read_csv('../model_predictions/vad_results_claude3.5sonnet.csv')\n",
    "        gt_df['Video Name'] = gt_df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "        gt_df = gt_df[gt_df['Video Name'].isin(merged.index)]\n",
    "        ground_truth = gt_df.set_index('Video Name')['True Label']\n",
    "        \n",
    "        # Majority voting\n",
    "        majority_vote = merged.mode(axis=1)[0]\n",
    "        \n",
    "        # Align ground truth\n",
    "        y_true = ground_truth.loc[merged.index]\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, majority_vote)\n",
    "        prec = precision_score(y_true, majority_vote,  average='macro',zero_division=0)\n",
    "        rec = recall_score(y_true, majority_vote, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, majority_vote, average='macro', zero_division=0)\n",
    "        \n",
    "        all_results.append({\n",
    "            'P': P,\n",
    "            'Num Videos': len(merged),\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"[P={P}] Processed {len(merged)} videos | Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save final results to one Excel file\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_df.to_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref.xlsx', index=False)\n",
    "    print(\"[Saved] VAD_Majority_Voting_Summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b3fdd-f02b-46a1-b08f-2581789986cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"claude3.5sonnet\",\n",
    "    \"claude3.5\",\n",
    "    \"claude3.7\",\n",
    "    \"gpt4o-mini\",\n",
    "    \"gpt4o\"\n",
    "]\n",
    "# P values representing percent of videos excluded as high-uncertainty\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "    \n",
    "    # Store results for each P\n",
    "    all_results = []\n",
    "    \n",
    "    for P in P_set:\n",
    "        \n",
    "        try:\n",
    "            low = pd.read_excel(f'low list/S_low_videos_{P}_{suffix}_ref_train.xlsx')\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load S_low_videos_{P}_trace.xlsx: {e}\")\n",
    "            continue\n",
    "        \n",
    "        low_list = low['video_name'].str.replace('.jpg', '', regex=False)\n",
    "        \n",
    "        # Store predictions per model\n",
    "        model_preds = {}\n",
    "        \n",
    "        for model in model_names:\n",
    "            try:\n",
    "                df = pd.read_csv(f'../model_predictions/vad_results_{model}.csv')\n",
    "                df['Video Name'] = df['Video Name'].str.replace('.jpg', '', regex=False)\n",
    "                df = df[df['Video Name'].isin(low_list)]\n",
    "                model_preds[model] = df[['Video Name', 'Predicted Label']].set_index('Video Name')\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Failed to process {model}: {e}\")\n",
    "        \n",
    "        # Merge all predictions\n",
    "        merged = pd.DataFrame(index=low_list)\n",
    "        for model in model_names:\n",
    "            merged[model] = model_preds.get(model, pd.DataFrame()).reindex(low_list)['Predicted Label']\n",
    "        \n",
    "        # Drop rows with missing predictions\n",
    "        merged = merged.dropna()\n",
    "        \n",
    "        if merged.empty:\n",
    "            print(f\"[Warning] No valid data for P={P}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Load ground truth from claude-3-5-sonnet\n",
    "        gt_df = pd.read_csv('../model_predictions/vad_results_claude3.5sonnet.csv')\n",
    "        gt_df['Video Name'] = gt_df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "        gt_df = gt_df[gt_df['Video Name'].isin(merged.index)]\n",
    "        ground_truth = gt_df.set_index('Video Name')['True Label']\n",
    "        \n",
    "        # Majority voting\n",
    "        majority_vote = merged.mode(axis=1)[0]\n",
    "        \n",
    "        # Align ground truth\n",
    "        y_true = ground_truth.loc[merged.index]\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, majority_vote)\n",
    "        prec = precision_score(y_true, majority_vote,  average='macro',zero_division=0)\n",
    "        rec = recall_score(y_true, majority_vote, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, majority_vote, average='macro', zero_division=0)\n",
    "        \n",
    "        all_results.append({\n",
    "            'P': P,\n",
    "            'Num Videos': len(merged),\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"[P={P}] Processed {len(merged)} videos | Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save final results to one Excel file\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_df.to_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref_train.xlsx', index=False)\n",
    "    print(\"[Saved] VAD_Majority_Voting_Summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d28629-f8f1-4dd2-8d36-ead1ecb33d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Load the summary files\n",
    "    majority_df = pd.read_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref.xlsx')\n",
    "    \n",
    "    # Extract metrics\n",
    "    P_values = majority_df['P']\n",
    "    overall_accuracy = majority_df['Accuracy']\n",
    "    # recall = majority_df['Recall']\n",
    "    # vague_abnormal_accuracy = vague_df['Accuracy']\n",
    "    \n",
    "    # Combine into final DataFrame\n",
    "    out_df = pd.DataFrame({\n",
    "        'P': P_values,\n",
    "        'Overall Accuracy': overall_accuracy\n",
    "        # 'Recall': recall,\n",
    "        # 'Vague Abnormal Accuracy': vague_abnormal_accuracy\n",
    "    })\n",
    "    \n",
    "    # Remove final two rows\n",
    "    out_df = out_df.iloc[:, :]\n",
    "    \n",
    "    # Save to xlsx\n",
    "    out_df.to_excel(f'low list/results_P_{suffix}_ref.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
