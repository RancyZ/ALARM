{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd21dc-0077-4f25-85e1-a43b8bf01b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zeroshot\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "from openai import OpenAI\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=\"API_KEY\")\n",
    "# Convert image to base64 string\n",
    "def convert_image_to_base64(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    _, buffer = cv2.imencode(\".jpg\", image)\n",
    "    return base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "# Analyze a single image using GPT-4 API\n",
    "def analyze_image(client, image_path):\n",
    "    base64Image = convert_image_to_base64(image_path)\n",
    "\n",
    "\n",
    "    prompt_message = (\n",
    " \"Please provide a prediction of the wound type in the image.\\n\"\n",
    "    \"Please respond using the format below:\\n\"\n",
    "    \"{\\n\"\n",
    "' “Type\": One of the following: “Stab Wound”,  “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions”\\n'\n",
    "    \"}\\n\"\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                prompt_message,\n",
    "                {\"image\": base64Image, \"resize\": 768},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        #\"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "        \n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(**params)\n",
    "        text = result.choices[0].message.content\n",
    "        return text, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# List images in the local directory and subdirectories\n",
    "def list_local_images(directory):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(image_path, directory)\n",
    "                image_files.append(relative_path.replace(os.sep, '/'))\n",
    "    return image_files\n",
    "\n",
    "# Process images in batches\n",
    "def batch_process_images(client, images, directory, batch_size, output_filename):\n",
    "    responses = []\n",
    "    processing_times = []\n",
    "\n",
    "    def process_image(image):\n",
    "        image_path = os.path.join(directory, image)\n",
    "        start_time = time.time()\n",
    "        response_text, processing_time = analyze_image(client, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if processing_time is None:\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "        response = {image: response_text}\n",
    "        with open(output_filename, \"a\") as f:\n",
    "            f.write(json.dumps(response) + \"\\n\")\n",
    "\n",
    "        return image, response_text, processing_time\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            print(\"batch:\", i)\n",
    "            futures = []\n",
    "            batch = images[i:i + batch_size]\n",
    "            for image in batch:\n",
    "                futures.append(executor.submit(process_image, image))\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                image_name, response_text, processing_time = future.result()\n",
    "                responses.append({image_name: response_text})\n",
    "                processing_times.append((image_name, processing_time))\n",
    "    return responses, processing_times\n",
    "\n",
    "def save_responses_to_file(responses, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(responses, f, indent=4)\n",
    "\n",
    "def main_part(directory, model_type, batch_size):\n",
    "    images = list_local_images(directory)\n",
    "    print(f\"Found {len(images)} images in {directory} and subdirectories.\")\n",
    "\n",
    "    output_dir = \"response_baseline/zero shot\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    jsonl_filename = os.path.join(output_dir, f'responses_{model_type}_images.jsonl')\n",
    "    json_filename = os.path.join(output_dir, f'responses_{model_type}_images.json')\n",
    "\n",
    "    responses, processing_times = batch_process_images(client, images, directory, batch_size, output_filename=jsonl_filename)\n",
    "\n",
    "    for response in responses:\n",
    "        print(response)\n",
    "\n",
    "    save_responses_to_file(responses, filename=json_filename)\n",
    "    print(\"Responses saved to json\")\n",
    "\n",
    "    df_time = pd.DataFrame(processing_times, columns=['Image Name', 'Processing Time'])\n",
    "    df_time['Image Name'] = df_time['Image Name'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "    return jsonl_filename, df_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = os.getcwd()\n",
    "    directory = os.path.join(current_dir, \"dataset\")  # Folder with images\n",
    "    batch_size = 10\n",
    "    # model_type = 'gpt4o-mini'\n",
    "    model_type = 'gpt4o'\n",
    "    filename, df_time = main_part(directory, model_type, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296c61b-039e-490d-83e5-6f1663aa9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain of thought\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "from openai import OpenAI\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=\"API_KEY\")\n",
    "\n",
    "# Convert image to base64 string\n",
    "def convert_image_to_base64(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    _, buffer = cv2.imencode(\".jpg\", image)\n",
    "    return base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "# Analyze a single image using GPT-4 API\n",
    "def analyze_image(client, image_path):\n",
    "    base64Image = convert_image_to_base64(image_path)\n",
    "\n",
    "\n",
    "\n",
    "    prompt_message = (\n",
    " \"You are a medical expert specializing in wound. You will be shown an image from a patient. Your task is to provide a prediction of the wound type in the image from the following seven categories: “Stab Wound”,  “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions”.\\n\"\n",
    "    \"Please respond using the format below:\\n\"\n",
    "    \"{\\n\"\n",
    "    '  \"description\": \"Provide a concise description of the image, including details such as size, shape, color, depth, exudate, tissue type (e.g., necrotic, granulating), surrounding skin condition, and any other relevant observations. (max 200 words)\"\\n'\n",
    "' \"reasoning\": \"Detailed reasoning for why this wound corresponds to the predicted category based on features. (max 100 words)\",\\n'\n",
    "' “Type\": One of the following: “Stab Wound”,  “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions”\\n'\n",
    "    \"}\\n\"\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                prompt_message,\n",
    "                {\"image\": base64Image, \"resize\": 768},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        # \"model\": \"gpt-4o\",\n",
    "        \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "        \n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(**params)\n",
    "        text = result.choices[0].message.content\n",
    "        return text, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# List images in the local directory and subdirectories\n",
    "def list_local_images(directory):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(image_path, directory)\n",
    "                image_files.append(relative_path.replace(os.sep, '/'))\n",
    "    return image_files\n",
    "\n",
    "# Process images in batches\n",
    "def batch_process_images(client, images, directory, batch_size, output_filename):\n",
    "    responses = []\n",
    "    processing_times = []\n",
    "\n",
    "    def process_image(image):\n",
    "        image_path = os.path.join(directory, image)\n",
    "        start_time = time.time()\n",
    "        response_text, processing_time = analyze_image(client, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if processing_time is None:\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "        response = {image: response_text}\n",
    "        with open(output_filename, \"a\") as f:\n",
    "            f.write(json.dumps(response) + \"\\n\")\n",
    "\n",
    "        return image, response_text, processing_time\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            print(\"batch:\", i)\n",
    "            futures = []\n",
    "            batch = images[i:i + batch_size]\n",
    "            for image in batch:\n",
    "                futures.append(executor.submit(process_image, image))\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                image_name, response_text, processing_time = future.result()\n",
    "                responses.append({image_name: response_text})\n",
    "                processing_times.append((image_name, processing_time))\n",
    "    return responses, processing_times\n",
    "\n",
    "def save_responses_to_file(responses, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(responses, f, indent=4)\n",
    "\n",
    "def main_part(directory, model_type, batch_size):\n",
    "    images = list_local_images(directory)\n",
    "    print(f\"Found {len(images)} images in {directory} and subdirectories.\")\n",
    "\n",
    "    output_dir = \"response\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    jsonl_filename = os.path.join(output_dir, f'responses_{model_type}_images_hyp_1.jsonl')\n",
    "    json_filename = os.path.join(output_dir, f'responses_{model_type}_images_hyp_1.json')\n",
    "\n",
    "    responses, processing_times = batch_process_images(client, images, directory, batch_size, output_filename=jsonl_filename)\n",
    "\n",
    "    for response in responses:\n",
    "        print(response)\n",
    "\n",
    "    save_responses_to_file(responses, filename=json_filename)\n",
    "    print(\"Responses saved to json\")\n",
    "\n",
    "    df_time = pd.DataFrame(processing_times, columns=['Image Name', 'Processing Time'])\n",
    "    df_time['Image Name'] = df_time['Image Name'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "    return jsonl_filename, df_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = os.getcwd()\n",
    "    directory = os.path.join(current_dir, \"dataset\")  # Folder with images\n",
    "    batch_size = 10\n",
    "    model_type = 'gpt4o-mini'\n",
    "    filename, df_time = main_part(directory, model_type, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8a52d-89dc-45da-ad3a-b91cb2a9e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fewshot\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "from openai import OpenAI\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=\"API_KEY\")\n",
    "# Convert image to base64 string\n",
    "def convert_image_to_base64(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    _, buffer = cv2.imencode(\".jpg\", image)\n",
    "    return base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "# Analyze a single image using GPT-4 API\n",
    "def analyze_image(client, image_path):\n",
    "    base64Image = convert_image_to_base64(image_path)\n",
    "\n",
    "\n",
    "\n",
    "    prompt_message = (f\"\"\"\n",
    "You are a medical expert specializing in wound. You are provided with 3 reference examples of wound analysis. \n",
    "Your task is to review the provided examples and provide a prediction of the wound type in the image from the following seven categories: \n",
    "“Stab Wound”, “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions\".\n",
    "\n",
    "# Reference Examples:\n",
    "1. Example 1:\n",
    "{{\n",
    "  \"description\": \"The image shows a wound on the skin with irregular, jagged edges. The wound is red and appears to have some depth, with possible minor bleeding. The surrounding skin is slightly red and inflamed, indicating irritation or trauma. There is no significant exudate visible, and the tissue appears raw but not necrotic.\",\n",
    "  \"reasoning\": \"The irregular, jagged edges and the appearance of the wound suggest it is an abrasion. Abrasions are characterized by jagged skin and minor bleeding. The absence of a puncture or burn pattern supports this classification.\",\n",
    "  \"Type\": \"Abrasions\"\n",
    "}}\n",
    "\n",
    "2. Example 2:\n",
    "{{\n",
    "  \"description\": \"The image shows a linear wound with clean, sharp edges, approximately several centimeters in length. The wound is open and appears to be of moderate depth, with visible red tissue and some bleeding. The surrounding skin is slightly reddened but otherwise intact. There is no significant swelling or bruising around the wound. The tissue within the wound appears fresh, with no signs of necrosis or granulation.\",\n",
    "  \"reasoning\": \"The characteristics of the wound, including its linear shape, clean edges, and moderate depth, are indicative of a Cut. Cuts are typically caused by sharp objects and result in clean cuts with bleeding, as seen in the image.\",\n",
    "  \"Type\": \"Cut\"\n",
    "}}\n",
    "\n",
    "3. Example 3:\n",
    "{{\n",
    "  \"description\": \"The image shows a wound with a reddish, irregular shape, surrounded by a purplish discoloration. The wound appears shallow with no significant depth and has a moist appearance. The surrounding skin shows signs of red and purple hues, indicating possible trauma. There is no visible necrotic tissue, and the area does not appear to have significant exudate. The skin around the wound is slightly swollen, suggesting inflammation.\",\n",
    "  \"reasoning\": \"The presence of a reddish, irregular wound with surrounding purplish discoloration and swelling suggests trauma. Blood vessels are damaged under the skin.\",\n",
    "  \"Type\": \"Laceration\"\n",
    "}}\n",
    "\n",
    "Please think step-by-step and respond using the format below:\n",
    "        {{\n",
    "        \"description\": \"Provide a concise description of the image, including details such as size, shape, color, depth, exudate, tissue type (e.g., necrotic, granulating), surrounding skin condition, and any other relevant observations. (max 200 words)\",\n",
    "        \"reasoning\": \"Detailed reasoning for why this wound corresponds to the predicted category based on features. (max 100 words)\",\n",
    "        \"Type\": One of the following: “Stab Wound”, “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions”\n",
    "        }}\n",
    "\"\"\"\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                prompt_message,\n",
    "                {\"image\": base64Image, \"resize\": 768},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        #\"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "        \n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(**params)\n",
    "        text = result.choices[0].message.content\n",
    "        return text, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# List images in the local directory and subdirectories\n",
    "def list_local_images(directory):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(image_path, directory)\n",
    "                image_files.append(relative_path.replace(os.sep, '/'))\n",
    "    return image_files\n",
    "\n",
    "# Process images in batches\n",
    "def batch_process_images(client, images, directory, batch_size, output_filename):\n",
    "    responses = []\n",
    "    processing_times = []\n",
    "\n",
    "    def process_image(image):\n",
    "        image_path = os.path.join(directory, image)\n",
    "        start_time = time.time()\n",
    "        response_text, processing_time = analyze_image(client, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if processing_time is None:\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "        response = {image: response_text}\n",
    "        with open(output_filename, \"a\") as f:\n",
    "            f.write(json.dumps(response) + \"\\n\")\n",
    "\n",
    "        return image, response_text, processing_time\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            print(\"batch:\", i)\n",
    "            futures = []\n",
    "            batch = images[i:i + batch_size]\n",
    "            for image in batch:\n",
    "                futures.append(executor.submit(process_image, image))\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                image_name, response_text, processing_time = future.result()\n",
    "                responses.append({image_name: response_text})\n",
    "                processing_times.append((image_name, processing_time))\n",
    "    return responses, processing_times\n",
    "\n",
    "def save_responses_to_file(responses, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(responses, f, indent=4)\n",
    "\n",
    "def main_part(directory, model_type, batch_size):\n",
    "    images = list_local_images(directory)\n",
    "    print(f\"Found {len(images)} images in {directory} and subdirectories.\")\n",
    "\n",
    "    output_dir = \"response_baseline/few shot\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    jsonl_filename = os.path.join(output_dir, f'responses_{model_type}_images.jsonl')\n",
    "    json_filename = os.path.join(output_dir, f'responses_{model_type}_images.json')\n",
    "\n",
    "    responses, processing_times = batch_process_images(client, images, directory, batch_size, output_filename=jsonl_filename)\n",
    "\n",
    "    for response in responses:\n",
    "        print(response)\n",
    "\n",
    "    save_responses_to_file(responses, filename=json_filename)\n",
    "    print(\"Responses saved to json\")\n",
    "\n",
    "    df_time = pd.DataFrame(processing_times, columns=['Image Name', 'Processing Time'])\n",
    "    df_time['Image Name'] = df_time['Image Name'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "    return jsonl_filename, df_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = os.getcwd()\n",
    "    directory = os.path.join(current_dir, \"dataset\")  # Folder with images\n",
    "    batch_size = 10\n",
    "    # model_type = 'gpt4o-mini'\n",
    "    model_type = 'gpt4o'\n",
    "    filename, df_time = main_part(directory, model_type, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a08924-2e8a-4bb1-937e-cba839c75bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICL\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "from openai import OpenAI\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=\"API_KEY\")\n",
    "# Convert image to base64 string\n",
    "def convert_image_to_base64(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    _, buffer = cv2.imencode(\".jpg\", image)\n",
    "    return base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "# Analyze a single image using GPT-4 API\n",
    "def analyze_image(client, image_path):\n",
    "    base64Image = convert_image_to_base64(image_path)\n",
    "\n",
    "\n",
    "    prompt_message = (f\"\"\"\n",
    "You are a medical expert specializing in wound. You are provided with a set of rules for wound prediction.\n",
    "Your task is to review the provided rules and provide a prediction of the wound type in the image from the following seven categories: \n",
    "“Stab Wound”, “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions\".\n",
    "\n",
    "The rules provided for wound prediction are: \n",
    "\"Stab Wound: Puncture-like wound with narrow entry, often deep and sharply defined; minimal surface tearing.\",\n",
    "\"Laceration: Irregular, jagged wound with torn or split skin, often caused by blunt trauma.\",\n",
    "\"Ingrown Nails: Redness, swelling, and possible pus near toenail or fingernail edges, often with nail edge embedded in skin.\",\n",
    "\"Cut: Clean, linear break in the skin, usually shallow and caused by sharp objects like knives.\",\n",
    "\"Burns: Reddened, blistered, or charred skin with varying depth; may appear dry, leathery, or moist depending on severity.\",\n",
    "\"Bruises: Discoloration under intact skin (blue, purple, green, or yellow), typically caused by blunt force trauma without open wound.\",\n",
    "\"Abrasions: Superficial scraping of the skin surface, often with visible raw or red areas and minimal bleeding.\"\n",
    "\n",
    "Please think step-by-step and respond using the format below:\n",
    "        {{\n",
    "        \"description\": \"Provide a concise description of the image, including details such as size, shape, color, depth, exudate, tissue type (e.g., necrotic, granulating), surrounding skin condition, and any other relevant observations. (max 200 words)\",\n",
    "        \"reasoning\": \"Detailed reasoning for why this wound corresponds to the predicted category based on features. (max 100 words)\",\n",
    "        \"Type\": One of the following: “Stab Wound”, “Laceration”, “Ingrown Nails”, “Cut”, “Burns”, “Bruises”, “Abrasions”\n",
    "        }}\n",
    "\"\"\"\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "    prompt_messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                prompt_message,\n",
    "                {\"image\": base64Image, \"resize\": 768},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        #\"model\": \"gpt-4o\",\n",
    "        \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "        \n",
    "        \"messages\": prompt_messages,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(**params)\n",
    "        text = result.choices[0].message.content\n",
    "        return text, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# List images in the local directory and subdirectories\n",
    "def list_local_images(directory):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(image_path, directory)\n",
    "                image_files.append(relative_path.replace(os.sep, '/'))\n",
    "    return image_files\n",
    "\n",
    "# Process images in batches\n",
    "def batch_process_images(client, images, directory, batch_size, output_filename):\n",
    "    responses = []\n",
    "    processing_times = []\n",
    "\n",
    "    def process_image(image):\n",
    "        image_path = os.path.join(directory, image)\n",
    "        start_time = time.time()\n",
    "        response_text, processing_time = analyze_image(client, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if processing_time is None:\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "        response = {image: response_text}\n",
    "        with open(output_filename, \"a\") as f:\n",
    "            f.write(json.dumps(response) + \"\\n\")\n",
    "\n",
    "        return image, response_text, processing_time\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            print(\"batch:\", i)\n",
    "            futures = []\n",
    "            batch = images[i:i + batch_size]\n",
    "            for image in batch:\n",
    "                futures.append(executor.submit(process_image, image))\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                image_name, response_text, processing_time = future.result()\n",
    "                responses.append({image_name: response_text})\n",
    "                processing_times.append((image_name, processing_time))\n",
    "    return responses, processing_times\n",
    "\n",
    "def save_responses_to_file(responses, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(responses, f, indent=4)\n",
    "\n",
    "def main_part(directory, model_type, batch_size):\n",
    "    images = list_local_images(directory)\n",
    "    print(f\"Found {len(images)} images in {directory} and subdirectories.\")\n",
    "\n",
    "    output_dir = \"response_baseline/ICL\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    jsonl_filename = os.path.join(output_dir, f'responses_{model_type}_images.jsonl')\n",
    "    json_filename = os.path.join(output_dir, f'responses_{model_type}_images.json')\n",
    "\n",
    "    responses, processing_times = batch_process_images(client, images, directory, batch_size, output_filename=jsonl_filename)\n",
    "\n",
    "    for response in responses:\n",
    "        print(response)\n",
    "\n",
    "    save_responses_to_file(responses, filename=json_filename)\n",
    "    print(\"Responses saved to json\")\n",
    "\n",
    "    df_time = pd.DataFrame(processing_times, columns=['Image Name', 'Processing Time'])\n",
    "    df_time['Image Name'] = df_time['Image Name'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "    return jsonl_filename, df_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_dir = os.getcwd()\n",
    "    directory = os.path.join(current_dir, \"dataset\")  # Folder with images\n",
    "    batch_size = 10\n",
    "    model_type = 'gpt4o-mini'\n",
    "    #model_type = 'gpt4o'\n",
    "    filename, df_time = main_part(directory, model_type, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
