{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a68745-4178-483a-92f1-98ba5fa87b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}\"\n",
    " \n",
    "    # ---------------- 1. Load Training Sets ----------------\n",
    "    prob_train_df = pd.read_excel(f\"../ref/model_prediction_probabilities_{suffix}_reas_train.xlsx\")\n",
    "    weighted_mse_train_df = pd.read_excel(f\"../reas/mse_difference_reasoningUS_{suffix}_reas_train.xlsx\")\n",
    "    mse_train_df = pd.read_excel(f\"../desc/optimal_c_and_mse_lstsq_with_name_{suffix}_desc_train.xlsx\") \n",
    "    \n",
    "    \n",
    "    # ---------------- 2. Clean video_name columns ----------------\n",
    "    for df in [prob_train_df, weighted_mse_train_df, mse_train_df]:\n",
    "        df[\"video_name\"] = df[\"video_name\"].str.replace(\".mp4\", \"\", regex=False)\n",
    "    \n",
    "    # ---------------- 3. Define (X-mean)/sigma Normalization Function ----------------\n",
    "    def mean_std_norm(series):\n",
    "        mean = series.mean()\n",
    "        std = series.std()\n",
    "        if std == 0:\n",
    "            return pd.Series(0.0, index=series.index)\n",
    "        return (series - mean) / std\n",
    "    \n",
    "    # ---------------- 4. Normalize Columns ----------------\n",
    "    prob_train_df[\"S3\"] = mean_std_norm(prob_train_df[\"average_prob\"])\n",
    "    weighted_mse_train_df[\"S2\"] = mean_std_norm(weighted_mse_train_df[\"MSE_difference\"])\n",
    "    mse_train_df[\"S1\"] = mean_std_norm(mse_train_df[\"MSE\"])\n",
    "    \n",
    "    # ---------------- 5. Merge into One DataFrame ----------------\n",
    "    merged_df = mse_train_df[[\"video_name\", \"S1\"]].merge(\n",
    "        weighted_mse_train_df[[\"video_name\", \"S2\"]], on=\"video_name\"\n",
    "    ).merge(\n",
    "        prob_train_df[[\"video_name\", \"S3\"]], on=\"video_name\"\n",
    "    )\n",
    "    \n",
    "    # ---------------- 6. Save Combined File ----------------\n",
    "    out_dir = \"low list\"\n",
    "    # os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    merged_df.to_excel(os.path.join(out_dir, f\"combined_normalized_training_sets_meansigma_{suffix}.xlsx\"), index=False)\n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724b3b6-7bc4-4f39-b402-c6c1eb3d6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Paths and parameters\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}\"\n",
    "    \n",
    "    \n",
    "    uncertainty_file = f'low list/combined_normalized_training_sets_meansigma_{suffix}.xlsx'\n",
    "    \n",
    "    \n",
    "    model_names = [\"claude-3-5-sonnet\", \"flash\", \"gpt-4o-mini\", \"gpt4o\", \"pro\"]\n",
    "    P_SET = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "    \n",
    "    # Load uncertainty scores\n",
    "    uncertainty_df = pd.read_excel(uncertainty_file)\n",
    "    uncertainty_df = uncertainty_df.rename(columns={'S1': 'S_data', 'S2': 'S_task', 'S3': 'S_ref'})\n",
    "    uncertainty_df['video_name'] = uncertainty_df['video_name'].str.replace('.mp4', '', regex=False)\n",
    "    uncertainty_df = uncertainty_df.set_index('video_name')\n",
    "    \n",
    "    # Load all models' predictions and ground truth\n",
    "    preds = []\n",
    "    for model in model_names:\n",
    "        df = pd.read_csv(f'../../LLM_output_generation/vad_results_{model}.csv')\n",
    "        df['Video Name'] = df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "        df = df.set_index('Video Name')\n",
    "        preds.append(df[['Predicted Label']].rename(columns={'Predicted Label': model}))\n",
    "    merged_preds_df = pd.concat(preds, axis=1)\n",
    "    merged_preds_df['majority_vote'] = merged_preds_df.mode(axis=1)[0]\n",
    "    ground_truth = pd.read_csv('../../../anomaly_taxonomy/vad_results_claude-3-5-sonnet.csv')\n",
    "    ground_truth['Video Name'] = ground_truth['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "    merged_preds_df['True_Label'] = ground_truth.set_index('Video Name').loc[merged_preds_df.index]['True Label']\n",
    "    \n",
    "    # Merge uncertainty with predictions and ground truth\n",
    "    combined_df = uncertainty_df.join(merged_preds_df.dropna(subset=['True_Label', 'majority_vote']), how='inner')\n",
    "    \n",
    "    # Grid search over alpha combinations and P values\n",
    "    alpha_grid = np.linspace(0, 1, 11)\n",
    "    results = []\n",
    "    \n",
    "    for p_val in P_SET:\n",
    "        for alpha1 in alpha_grid:\n",
    "            for alpha2 in alpha_grid:\n",
    "                if alpha1 + alpha2 > 1.0:\n",
    "                    continue\n",
    "                alpha3 = 1.0 - alpha1 - alpha2\n",
    "                s_total = (alpha1 * combined_df['S_data'] +\n",
    "                           alpha2 * combined_df['S_task'] +\n",
    "                           alpha3 * combined_df['S_ref'])\n",
    "                tau = np.percentile(s_total, 100 - p_val)\n",
    "                low_uncertainty_df = combined_df[s_total <= tau]\n",
    "    \n",
    "                if not low_uncertainty_df.empty:\n",
    "                    acc = accuracy_score(low_uncertainty_df['True_Label'], low_uncertainty_df['majority_vote'])\n",
    "                    results.append({\n",
    "                        'P': p_val,\n",
    "                        'alpha1': round(alpha1, 2),\n",
    "                        'alpha2': round(alpha2, 2),\n",
    "                        'alpha3': round(alpha3, 2),\n",
    "                        'accuracy': round(acc, 4),\n",
    "                        'num_videos_kept': len(low_uncertainty_df)\n",
    "                    })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_excel(f's_total_accuracy_over_P_and_x_real_labels_meansigma_train_{suffix}.xlsx', index=False)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef1c47-6df9-427a-92e3-eff7d1eb549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}\"\n",
    "\n",
    "\n",
    "    \n",
    "    # --- File paths ---\n",
    "    ref_file  = f\"../ref/low list/VAD_Majority_Voting_Summary_{suffix}_reas_ref_train.xlsx\"\n",
    "    reas_file = f\"../reas/low list/VAD_Majority_Voting_Summary_{suffix}_reas_train.xlsx\"\n",
    "    desc_file = f\"../desc/low list/VAD_Majority_Voting_Summary_sup_{suffix}_desc_train.xlsx\"\n",
    "    \n",
    "  \n",
    "    # --- Read P and Accuracy, rename Accuracy columns ---\n",
    "    ref_df  = pd.read_excel(ref_file,  usecols=[\"P\", \"Accuracy\"]).rename(columns={\"Accuracy\": \"Accuracy_s3\"})\n",
    "    reas_df = pd.read_excel(reas_file, usecols=[\"P\", \"Accuracy\"]).rename(columns={\"Accuracy\": \"Accuracy_s2\"})\n",
    "    desc_df = pd.read_excel(desc_file, usecols=[\"P\", \"Accuracy\"]).rename(columns={\"Accuracy\": \"Accuracy_s1\"})\n",
    "    \n",
    "    # --- Merge on P ---\n",
    "    merged_df = ref_df.merge(reas_df, on=\"P\").merge(desc_df, on=\"P\")\n",
    "    \n",
    "    # --- Save to a new Excel file ---\n",
    "    merged_df.to_excel(f\"low list/VAD_Majority_Voting_P_Accuracy_Combined_{suffix}_train.xlsx\", index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c7db9-508d-42e7-8bc3-e580cb72ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define folds\n",
    "folds = [f'fold{i}' for i in range(5)]\n",
    "\n",
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "# Process each fold\n",
    "for fold in folds:\n",
    "    # Construct file paths\n",
    "    acc_file = f's_total_accuracy_over_P_and_x_real_labels_meansigma_train_{fold}.xlsx'\n",
    "    base_file = f'low list/VAD_Majority_Voting_P_Accuracy_Combined_{fold}_train.xlsx'\n",
    "\n",
    "    # Load data\n",
    "    accuracy_df = pd.read_excel(acc_file)\n",
    "    baseline_df = pd.read_excel(base_file)\n",
    "\n",
    "    # Merge by P\n",
    "    merged_df = pd.merge(accuracy_df, baseline_df[['P', 'Accuracy_s1', 'Accuracy_s2', 'Accuracy_s3']], on='P', how='left')\n",
    "\n",
    "    # Compute min difference\n",
    "    merged_df['min_diff'] = merged_df.apply(\n",
    "        lambda row: min(row['accuracy'] - row['Accuracy_s1'],\n",
    "                        row['accuracy'] - row['Accuracy_s2'],\n",
    "                        row['accuracy'] - row['Accuracy_s3']), axis=1)\n",
    "\n",
    "    # Group and average\n",
    "    grouped = merged_df.groupby(['P', 'alpha1', 'alpha2', 'alpha3'])['min_diff'].mean().reset_index()\n",
    "\n",
    "    # Store per (P, alpha1, alpha2, alpha3)\n",
    "    for _, row in grouped.iterrows():\n",
    "        key = (row['P'], row['alpha1'], row['alpha2'], row['alpha3'])\n",
    "        if key not in all_results:\n",
    "            all_results[key] = []\n",
    "        all_results[key].append(row['min_diff'])\n",
    "\n",
    "# Aggregate across folds\n",
    "aggregated_results = []\n",
    "for (P, a1, a2, a3), values in all_results.items():\n",
    "    aggregated_results.append({\n",
    "        'P': P,\n",
    "        'alpha1': a1,\n",
    "        'alpha2': a2,\n",
    "        'alpha3': a3,\n",
    "        'mean_min_diff': np.mean(values)\n",
    "    })\n",
    "\n",
    "aggregated_df = pd.DataFrame(aggregated_results)\n",
    "\n",
    "# Get best alpha per P\n",
    "best_alpha_per_P = aggregated_df.loc[aggregated_df.groupby('P')['mean_min_diff'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# Save result\n",
    "best_alpha_per_P.to_excel('best_alpha_combination_for_each_P_meansigma_train_all_folds.xlsx', index=False)\n",
    "print(\"✅ Saved to best_alpha_combination_for_each_P_meansigma_train_all_folds.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eeb7d4-6c84-4ed7-bd86-d03555448b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Load source files again\n",
    "\n",
    "\n",
    "    prob_df = pd.read_excel(f\"../ref/model_prediction_probabilities_{suffix}_reas.xlsx\")\n",
    "    weighted_mse_df = pd.read_excel(f\"../reas/mse_difference_reasoningUS_{suffix}_reas.xlsx\")\n",
    "    mse_df = pd.read_excel(f\"../desc/optimal_c_and_mse_lstsq_with_name_{suffix}_desc.xlsx\")\n",
    "    \n",
    "    prob_train_df = pd.read_excel(f\"../ref/model_prediction_probabilities_{suffix}_reas.xlsx\")\n",
    "    weighted_mse_train_df = pd.read_excel(f\"../reas/mse_difference_reasoningUS_{suffix}_reas.xlsx\")\n",
    "    mse_train_df = pd.read_excel(f\"../desc/optimal_c_and_mse_lstsq_with_name_{suffix}_desc.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Clean video_name columns\n",
    "    for df in [prob_df, weighted_mse_df, mse_df, prob_train_df, weighted_mse_train_df, mse_train_df]:\n",
    "        df['video_name'] = df['video_name'].str.replace('.mp4', '', regex=False)\n",
    "    \n",
    "    # Compute mean and sigma from training sets\n",
    "    prob_mean = prob_train_df['average_prob'].mean()\n",
    "    prob_sigma = prob_train_df['average_prob'].std()\n",
    "    mse_diff_mean = weighted_mse_train_df['MSE_difference'].mean()\n",
    "    mse_diff_sigma = weighted_mse_train_df['MSE_difference'].std()\n",
    "    mse_mean = mse_train_df['MSE'].mean()\n",
    "    mse_sigma = mse_train_df['MSE'].std()\n",
    "    \n",
    "    # Merge files\n",
    "    merged_df = prob_df.merge(weighted_mse_df[['video_name', 'MSE_difference']], on='video_name', how='left')\n",
    "    merged_df = merged_df.merge(mse_df[['video_name', 'MSE']], on='video_name', how='left')\n",
    "    \n",
    "    # Normalize using (X-mean) / sigma\n",
    "    merged_df['normalized_prob'] = (merged_df['average_prob'] - prob_mean) / prob_sigma\n",
    "    merged_df['normalized_MSE_difference'] = (merged_df['MSE_difference'] - mse_diff_mean) / mse_diff_sigma\n",
    "    merged_df['normalized_MSE'] = (merged_df['MSE'] - mse_mean) / mse_sigma\n",
    "    \n",
    "    # Load best alpha combinations\n",
    "    # best_alpha_df = pd.read_excel(\"best_alpha_combination_for_each_P_meansigma_train.xlsx\")\n",
    "    \n",
    "    \n",
    "    best_alpha_df = pd.read_excel(\"best_alpha_combination_for_each_P_meansigma_train_all_folds.xlsx\")\n",
    "    \n",
    "    \n",
    "    # Output with different sheets for each P\n",
    "    output_file = f\"combined_sum_output_with_best_alpha_per_P_{suffix}.xlsx\"\n",
    "    \n",
    "    #output_file = \"combined_sum_output_with_best_alpha_per_P_val.xlsx\"\n",
    "    \n",
    "    #os.makedirs(\"adaptive weight\", exist_ok=True)\n",
    "    \n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for _, row in best_alpha_df.iterrows():\n",
    "            P = row[\"P\"]\n",
    "            alpha1 = row[\"alpha1\"]\n",
    "            alpha2 = row[\"alpha2\"]\n",
    "            alpha3 = row[\"alpha3\"]\n",
    "    \n",
    "            merged_df[f'sum_value_P{P}'] = (\n",
    "                alpha1 * merged_df['normalized_MSE'] +\n",
    "                alpha2 * merged_df['normalized_MSE_difference'] +\n",
    "                alpha3 * merged_df['normalized_prob']\n",
    "            )\n",
    "    \n",
    "            merged_df[['video_name', 'normalized_MSE', 'normalized_MSE_difference',\n",
    "                       'normalized_prob', f'sum_value_P{P}']].to_excel(writer, sheet_name=f\"P_{P}\", index=False)\n",
    "    \n",
    "    print(f\"✅ Output saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead19bef-82c4-49ff-8794-0bc1a26b4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define file template and folds\n",
    "file_template = \"combined_sum_output_with_best_alpha_per_P_fold{}.xlsx\"\n",
    "\n",
    "folds = list(range(5))\n",
    "\n",
    "# Load sheet names from the first file\n",
    "sheet_names = pd.ExcelFile(file_template.format(0)).sheet_names\n",
    "\n",
    "# Dictionary to store results by sheet\n",
    "all_avg_dfs = {}\n",
    "\n",
    "# Process each sheet (P value) independently\n",
    "for sheet in sheet_names:\n",
    "    # Extract P value for the correct value column\n",
    "    match = re.search(r\"P_(\\d+\\.?\\d*)\", sheet)\n",
    "    if not match:\n",
    "        continue\n",
    "    p_value = match.group(1)\n",
    "    value_col = f\"sum_value_P{p_value}\"\n",
    "    \n",
    "\n",
    "    # Collect values across folds\n",
    "    video_values = {}\n",
    "    for fold in folds:\n",
    "        file_path = file_template.format(fold)\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "\n",
    "        if value_col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            video = row['video_name']\n",
    "            value = row[value_col]\n",
    "            if video not in video_values:\n",
    "                video_values[video] = []\n",
    "            video_values[video].append(value)\n",
    "\n",
    "    # Compute average for each video in this P\n",
    "    avg_data = {\n",
    "        'video_name': [],\n",
    "        'average_value': []\n",
    "    }\n",
    "\n",
    "    for video, values in video_values.items():\n",
    "        clean_values = [v for v in values if pd.notnull(v)]\n",
    "        if clean_values:\n",
    "            avg = sum(clean_values) / len(clean_values)\n",
    "            avg_data['video_name'].append(video)\n",
    "            avg_data['average_value'].append(avg)\n",
    "\n",
    "    avg_df = pd.DataFrame(avg_data)\n",
    "    all_avg_dfs[sheet] = avg_df\n",
    "\n",
    "# Save all to a single Excel file with one sheet per P\n",
    "with pd.ExcelWriter(\"average_video_values_by_P.xlsx\") as writer:\n",
    "    for sheet_name, df in all_avg_dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6254888-ddfb-4a78-9bbe-17591b52cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the combined sum output with multiple sheets\n",
    "\n",
    "file_path = \"average_video_values_by_P.xlsx\"\n",
    "\n",
    "\n",
    "# Define the P values you want to process\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "for P in P_set:\n",
    "    # Read corresponding sheet\n",
    "    sheet_df = pd.read_excel(file_path, sheet_name=f\"P_{P}.0\")\n",
    "\n",
    "    video_names = sheet_df['video_name'].astype(str).values\n",
    "    # uncertainty_scores = sheet_df[f'sum_value_P{P}.0'].values\n",
    "\n",
    "    uncertainty_scores = sheet_df['average_value'].values\n",
    "\n",
    "    tau = np.percentile(uncertainty_scores, 100 - P)\n",
    "    mask_low = uncertainty_scores <= tau\n",
    "    S_low_videos = video_names[mask_low]\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        \"video_name\": S_low_videos,\n",
    "        \"uncertainty\": uncertainty_scores[mask_low]\n",
    "    })\n",
    "\n",
    "    out_df.to_excel(f\"low list/S_low_videos_{P}_normalized_meansigma_bestalpha_average_5.xlsx\", index=False)\n",
    "\n",
    "\n",
    "    print(f\"[P = {P}] Threshold τ = {tau:.4f}\")\n",
    "    print(f\"Kept {len(S_low_videos)}/{len(video_names)} videos in S_low.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a126534-faa2-4710-99e5-4bab20ffda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model names\n",
    "model_names = [\"claude-3-5-sonnet\", \"flash\", \"gpt-4o-mini\", \"gpt4o\", \"pro\"]\n",
    "\n",
    "# P values representing percent of videos excluded as high-uncertainty\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "# Store results for each P\n",
    "all_results = []\n",
    "\n",
    "for P in P_set:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        low = pd.read_excel(f'low list/S_low_videos_{P}_normalized_meansigma_bestalpha_average_5.xlsx')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to load S_low_videos_{P}_trace.xlsx: {e}\")\n",
    "        continue\n",
    "    \n",
    "    low_list = low['video_name'].str.replace('.mp4', '', regex=False)\n",
    "    \n",
    "    # Store predictions per model\n",
    "    model_preds = {}\n",
    "    \n",
    "    for model in model_names:\n",
    "        try:\n",
    "            df = pd.read_csv(f'../../LLM_output_generation/vad_results_{model}.csv')\n",
    "            df['Video Name'] = df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "            df = df[df['Video Name'].isin(low_list)]\n",
    "            model_preds[model] = df[['Video Name', 'Predicted Label']].set_index('Video Name')\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to process {model}: {e}\")\n",
    "    \n",
    "    # Merge all predictions\n",
    "    merged = pd.DataFrame(index=low_list)\n",
    "    for model in model_names:\n",
    "        merged[model] = model_preds.get(model, pd.DataFrame()).reindex(low_list)['Predicted Label']\n",
    "    \n",
    "    # Drop rows with missing predictions\n",
    "    merged = merged.dropna()\n",
    "    \n",
    "    if merged.empty:\n",
    "        print(f\"[Warning] No valid data for P={P}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Load ground truth from claude-3-5-sonnet\n",
    "    gt_df = pd.read_csv('../../LLM_output_generation/vad_results_claude-3-5-sonnet.csv')\n",
    "    gt_df['Video Name'] = gt_df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "    gt_df = gt_df[gt_df['Video Name'].isin(merged.index)]\n",
    "    ground_truth = gt_df.set_index('Video Name')['True Label']\n",
    "    \n",
    "    # Majority voting\n",
    "    majority_vote = merged.mode(axis=1)[0]\n",
    "    \n",
    "    # Align ground truth\n",
    "    y_true = ground_truth.loc[merged.index]\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true, majority_vote)\n",
    "    prec = precision_score(y_true, majority_vote, zero_division=0)\n",
    "    rec = recall_score(y_true, majority_vote, zero_division=0)\n",
    "    f1 = f1_score(y_true, majority_vote, zero_division=0)\n",
    "    \n",
    "    all_results.append({\n",
    "        'P': P,\n",
    "        'Num Videos': len(merged),\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"[P={P}] Processed {len(merged)} videos | Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Save final results to one Excel file\n",
    "result_df = pd.DataFrame(all_results)\n",
    "result_df.to_excel(f'low list/VAD_Majority_Voting_Summary_normalized_meansigma_bestalpha_average_5.xlsx', index=False)\n",
    "\n",
    "print(\"[Saved] VAD_Majority_Voting_Summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb6f61-0527-486c-8c14-08f8db675bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the summary files\n",
    "majority_df = pd.read_excel(f'low list/VAD_Majority_Voting_Summary_normalized_meansigma_bestalpha_average_5.xlsx')\n",
    "\n",
    "\n",
    "# Extract metrics\n",
    "P_values = majority_df['P']\n",
    "overall_accuracy = majority_df['Accuracy']\n",
    "# recall = majority_df['Recall']\n",
    "# vague_abnormal_accuracy = vague_df['Accuracy']\n",
    "\n",
    "# Combine into final DataFrame\n",
    "out_df = pd.DataFrame({\n",
    "    'P': P_values,\n",
    "    'Overall Accuracy': overall_accuracy\n",
    "    # 'Recall': recall,\n",
    "    # 'Vague Abnormal Accuracy': vague_abnormal_accuracy\n",
    "})\n",
    "\n",
    "# Remove final two rows\n",
    "out_df = out_df.iloc[:, :]\n",
    "\n",
    "# Save to xlsx\n",
    "# out_df.to_excel(f'low list/results_P_normalized_meansigma_bestalpha_average_5.xlsx', index=False)\n",
    "\n",
    "\n",
    "out_df.to_excel(f'low list/results_P_normalized_meansigma_bestalpha_average_5_makeup.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064976ae-52ac-4557-a234-91e6a38379a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File template\n",
    "# file_template = \"separate result/results_P_sup_fold{}_desc.xlsx\"\n",
    "\n",
    "# file_template = \"separate result/results_P_fold{}_reas.xlsx\"\n",
    "\n",
    "file_template = \"../ref/low list/results_P_fold{}_reas_ref.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "folds = range(5)\n",
    "\n",
    "# Dictionary to collect accuracy per P across folds\n",
    "accuracy_by_P = {}\n",
    "\n",
    "# Load accuracy values from each fold\n",
    "for fold in folds:\n",
    "    df = pd.read_excel(file_template.format(fold))\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        P = row['P']  # assuming 'P' column exists\n",
    "        acc = row['Overall Accuracy']  # assuming 'overall_accuracy' column exists\n",
    "\n",
    "        if P not in accuracy_by_P:\n",
    "            accuracy_by_P[P] = []\n",
    "        accuracy_by_P[P].append(acc)\n",
    "\n",
    "# Compute average accuracy per P\n",
    "avg_accuracy = {\n",
    "    'P': [],\n",
    "    'average_overall_accuracy': []\n",
    "}\n",
    "\n",
    "for P, acc_list in accuracy_by_P.items():\n",
    "    avg_accuracy['P'].append(P)\n",
    "    avg_accuracy['average_overall_accuracy'].append(sum(acc_list) / len(acc_list))\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "avg_df = pd.DataFrame(avg_accuracy)\n",
    "# avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_desc.xlsx\", index=False)\n",
    "\n",
    "\n",
    "os.makedirs(\"separate result\", exist_ok=True)\n",
    "\n",
    "\n",
    "avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_reas_ref.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042819c9-0826-4abd-a8fd-c06880ae8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File template\n",
    "# file_template = \"separate result/results_P_sup_fold{}_desc.xlsx\"\n",
    "\n",
    "file_template = \"../reas/low list/results_P_fold{}_reas.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folds = range(5)\n",
    "\n",
    "# Dictionary to collect accuracy per P across folds\n",
    "accuracy_by_P = {}\n",
    "\n",
    "# Load accuracy values from each fold\n",
    "for fold in folds:\n",
    "    df = pd.read_excel(file_template.format(fold))\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        P = row['P']  # assuming 'P' column exists\n",
    "        acc = row['Overall Accuracy']  # assuming 'overall_accuracy' column exists\n",
    "\n",
    "        if P not in accuracy_by_P:\n",
    "            accuracy_by_P[P] = []\n",
    "        accuracy_by_P[P].append(acc)\n",
    "\n",
    "# Compute average accuracy per P\n",
    "avg_accuracy = {\n",
    "    'P': [],\n",
    "    'average_overall_accuracy': []\n",
    "}\n",
    "\n",
    "for P, acc_list in accuracy_by_P.items():\n",
    "    avg_accuracy['P'].append(P)\n",
    "    avg_accuracy['average_overall_accuracy'].append(sum(acc_list) / len(acc_list))\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "avg_df = pd.DataFrame(avg_accuracy)\n",
    "# avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_desc.xlsx\", index=False)\n",
    "\n",
    "\n",
    "os.makedirs(\"separate result\", exist_ok=True)\n",
    "\n",
    "\n",
    "avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_reas.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4154f53-35de-46c8-aa01-e30dbd922fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File template\n",
    "file_template = \"../desc/low list/results_P_sup_fold{}_desc.xlsx\"\n",
    "\n",
    "\n",
    "folds = range(5)\n",
    "\n",
    "# Dictionary to collect accuracy per P across folds\n",
    "accuracy_by_P = {}\n",
    "\n",
    "# Load accuracy values from each fold\n",
    "for fold in folds:\n",
    "    df = pd.read_excel(file_template.format(fold))\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        P = row['P']  # assuming 'P' column exists\n",
    "        acc = row['Overall Accuracy']  # assuming 'overall_accuracy' column exists\n",
    "\n",
    "        if P not in accuracy_by_P:\n",
    "            accuracy_by_P[P] = []\n",
    "        accuracy_by_P[P].append(acc)\n",
    "\n",
    "# Compute average accuracy per P\n",
    "avg_accuracy = {\n",
    "    'P': [],\n",
    "    'average_overall_accuracy': []\n",
    "}\n",
    "\n",
    "for P, acc_list in accuracy_by_P.items():\n",
    "    avg_accuracy['P'].append(P)\n",
    "    avg_accuracy['average_overall_accuracy'].append(sum(acc_list) / len(acc_list))\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "avg_df = pd.DataFrame(avg_accuracy)\n",
    "# avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_desc.xlsx\", index=False)\n",
    "\n",
    "\n",
    "os.makedirs(\"separate result\", exist_ok=True)\n",
    "\n",
    "\n",
    "avg_df.to_excel(\"separate result/average_overall_accuracy_by_P_desc.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
