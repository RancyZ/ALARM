{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce2bb4-7d75-44fe-b1a3-4b5b15828d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"../../LLM_output_generation/extracted_video_anomalies_all_models.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Initialize model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Define model names\n",
    "model_names = [\"claude-3-5-sonnet\", \"flash\", \"gpt-4o-mini\", \"gpt4o\", \"pro\"]\n",
    "\n",
    "# Prepare final DataFrame\n",
    "final_data = pd.DataFrame()\n",
    "final_data[\"video_name\"] = df[\"video_name\"]\n",
    "\n",
    "# Embed and extract selected fields\n",
    "for model_name in model_names:\n",
    "    # desc_col = f\"{model_name}-description\"\n",
    "    reas_col = f\"{model_name}-reasoning\"\n",
    "    anomaly_col = f\"{model_name}-anomaly\"\n",
    "\n",
    "    if desc_col in df.columns:\n",
    "        desc_texts = df[desc_col].tolist()\n",
    "        desc_embeds = []\n",
    "        for text in desc_texts:\n",
    "            if pd.isna(text):\n",
    "                desc_embeds.append(np.nan)\n",
    "            else:\n",
    "                desc_embeds.append(model.encode(text))\n",
    "        final_data[f\"{model_name}-desc_emb\"] = desc_embeds\n",
    "\n",
    "    if reas_col in df.columns:\n",
    "        reas_texts = df[reas_col].tolist()\n",
    "        reas_embeds = []\n",
    "        for text in reas_texts:\n",
    "            if pd.isna(text):\n",
    "                reas_embeds.append(np.nan)\n",
    "            else:\n",
    "                reas_embeds.append(model.encode(text))\n",
    "        final_data[f\"{model_name}-reas_emb\"] = reas_embeds\n",
    "\n",
    "    if anomaly_col in df.columns:\n",
    "        final_data[f\"{model_name}-anomaly\"] = df[anomaly_col]\n",
    "\n",
    "# Save to output file\n",
    "output_path = \"embedded_only_video_anomalies_reas_label.xlsx\"\n",
    "final_data.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Done! File saved as: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516d4d3-da08-4a83-a380-14677a62b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "model_names = [\n",
    "    \"claude-3-5-sonnet\",\n",
    "    \"flash\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt4o\",\n",
    "    \"pro\"\n",
    "]\n",
    "\n",
    "video_dict = {}\n",
    "\n",
    "for name in model_names:\n",
    "    file_path = f\"../../LLM_output_generation/handcraft_rule10_{name}.json\"\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {file_path}\")\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        data = json.loads(content)  # Load the entire dictionary\n",
    "\n",
    "    anomalies = {}\n",
    "\n",
    "    for video_name, response_text in data.items():\n",
    "        try:\n",
    "            if response_text is None:\n",
    "                anomaly_value = \"NAN\"\n",
    "            else:\n",
    "                response_json = json.loads(response_text)\n",
    "                anomaly_value = response_json.get('updated_anomaly', 'NAN')\n",
    "        except Exception:\n",
    "            anomaly_value = \"NAN\"\n",
    "\n",
    "        anomalies[video_name] = anomaly_value\n",
    "\n",
    "    for video_name, anomaly in anomalies.items():\n",
    "        if video_name not in video_dict:\n",
    "            video_dict[video_name] = {}\n",
    "        video_dict[video_name][f\"{name}-anomaly\"] = anomaly\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(video_dict, orient='index')\n",
    "df.index.name = \"video_name\"\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(\"extracted_video_anomalies_all_models_updated_all.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4a661-2f4a-4c57-86df-015833889386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two files\n",
    "file1 = \"embedded_only_video_anomalies_reas_label.xlsx\"\n",
    "file2 = \"extracted_video_anomalies_all_models_updated_all.xlsx\"\n",
    "\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "\n",
    "# Ensure consistent types for comparison\n",
    "df2['gpt-4o-mini-anomaly'] = pd.to_numeric(df2['gpt-4o-mini-anomaly'], errors='coerce')\n",
    "df2['gpt4o-anomaly'] = pd.to_numeric(df2['gpt4o-anomaly'], errors='coerce')\n",
    "df2['pro-anomaly'] = pd.to_numeric(df2['pro-anomaly'], errors='coerce')\n",
    "\n",
    "# Merge on video_name\n",
    "merged_df = pd.merge(df1, df2, on='video_name', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Compare anomalies for each model and create y indicators\n",
    "models = ['claude-3-5-sonnet', 'flash', 'gpt-4o-mini', 'gpt4o', 'pro']\n",
    "for model in models:\n",
    "    col1 = f\"{model}-anomaly_df1\"\n",
    "    col2 = f\"{model}-anomaly_df2\"\n",
    "    y_col = f\"{model}_y\"\n",
    "    merged_df[y_col] = (merged_df[col1] != merged_df[col2]).astype(int)\n",
    "\n",
    "# Keep only relevant columns and save to Excel\n",
    "output_cols = ['video_name'] + [f\"{model}_y\" for model in models]\n",
    "result_df = merged_df[output_cols]\n",
    "\n",
    "# Save the results\n",
    "result_df.to_excel(\"anomaly_label_comparison_y.xlsx\", index=False)\n",
    "print(\"✅ Done! File saved as anomaly_label_comparison_y.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27deb4-fd2a-4dbf-9b8e-3a701f5a14c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    # Load files\n",
    "    y_df = pd.read_excel('anomaly_label_comparison_y.xlsx')\n",
    "    features_df = pd.read_excel('embedded_only_video_anomalies_reas_label.xlsx')\n",
    "    rule_df = pd.read_excel('embedded_combined_handcraft_rule.xlsx')\n",
    "    train_videos_df = pd.read_excel(f'../reas/train_dataset_{suffix}.xlsx')\n",
    "    test_videos_df = pd.read_excel('../reas/test_dataset_reas.xlsx')\n",
    "    \n",
    "    # Rename 'test video' to 'video_name' in test dataset if needed\n",
    "    if 'test video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test video': 'video_name'}, inplace=True)\n",
    "    elif 'test_video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test_video': 'video_name'}, inplace=True)\n",
    "    \n",
    "    # Clean and parse rule embedding\n",
    "    rule_text_raw = rule_df['embedding'].iloc[0]\n",
    "    rule_text_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', rule_text_raw)\n",
    "    rule_embedding = np.array(eval(rule_text_clean))\n",
    "    \n",
    "    # Model list\n",
    "    model_list = ['claude-3-5-sonnet', 'flash', 'gpt-4o-mini', 'gpt4o', 'pro']\n",
    "    \n",
    "    # Training and test video names with .mp4 suffix\n",
    "    train_video_names = set(train_videos_df['video_name'].astype(str) + \".mp4\")\n",
    "    test_video_names = set(test_videos_df['video_name'].astype(str) + \".mp4\")\n",
    "    \n",
    "    # Store final results: video_name + 5 probabilities + average\n",
    "    prob_output = []\n",
    "    \n",
    "    # Initialize dict to store probabilities by model\n",
    "    prob_dict = {model: {} for model in model_list}\n",
    "    \n",
    "    # Loop over models\n",
    "    for model in model_list:\n",
    "        feature_list = []\n",
    "        y_list = []\n",
    "        video_name_list = []\n",
    "    \n",
    "        reas_emb_series = features_df[f\"{model}-reas_emb\"]\n",
    "        anomaly_series = features_df[f\"{model}-anomaly\"]\n",
    "        y_series = y_df[f\"{model}_y\"]\n",
    "        video_series = features_df['video_name']\n",
    "    \n",
    "        for emb_str, anom, label, vid in zip(reas_emb_series, anomaly_series, y_series, video_series):\n",
    "            if isinstance(emb_str, str):\n",
    "                emb_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', emb_str)\n",
    "                emb = np.array(eval(emb_clean))\n",
    "    \n",
    "                feature = np.concatenate([emb, [anom], rule_embedding])\n",
    "                feature_list.append(feature)\n",
    "                y_list.append(label)\n",
    "                video_name_list.append(vid)\n",
    "    \n",
    "        X = np.vstack(feature_list)\n",
    "        y = np.array(y_list)\n",
    "        video_names = np.array(video_name_list)\n",
    "    \n",
    "        # Split into train/test based on train/test datasets\n",
    "        train_idx = np.isin(video_names, list(train_video_names))\n",
    "        test_idx = np.isin(video_names, list(test_video_names))\n",
    "    \n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, video_test = X[test_idx], video_names[test_idx]\n",
    "    \n",
    "        model_lr = LogisticRegression(max_iter=1000)\n",
    "        model_lr.fit(X_train, y_train)\n",
    "    \n",
    "        # Predict probabilities on test set (probability of class 1)\n",
    "        probs = model_lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "        # Store probabilities by video name\n",
    "        for vid, prob in zip(video_test, probs):\n",
    "            prob_dict[model][vid] = prob\n",
    "    \n",
    "    # Collect all test video names (union from all models' outputs)\n",
    "    all_video_names = set()\n",
    "    for model_probs in prob_dict.values():\n",
    "        all_video_names.update(model_probs.keys())\n",
    "    \n",
    "    # Build final output\n",
    "    for vid in sorted(all_video_names):\n",
    "        row = {'video_name': vid}\n",
    "        prob_values = []\n",
    "        for model in model_list:\n",
    "            prob = prob_dict[model].get(vid, np.nan)\n",
    "            row[f\"{model}_prob\"] = prob\n",
    "            prob_values.append(prob)\n",
    "        row['average_prob'] = np.nanmean(prob_values)\n",
    "        prob_output.append(row)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_df = pd.DataFrame(prob_output)\n",
    "    output_df.to_excel(f\"model_prediction_probabilities_{suffix}.xlsx\", index=False)\n",
    "    \n",
    "    print(\"✅ Probability file saved as: model_prediction_probabilities.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0daee-13c2-4bf1-9a86-25b0355deadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    # Load files\n",
    "    y_df = pd.read_excel('anomaly_label_comparison_y.xlsx')\n",
    "    features_df = pd.read_excel('embedded_only_video_anomalies_reas_label.xlsx')\n",
    "    rule_df = pd.read_excel('embedded_combined_handcraft_rule.xlsx')\n",
    "    train_videos_df = pd.read_excel(f'../reas/train_dataset_{suffix}.xlsx')\n",
    "    # test_videos_df = pd.read_excel('test_dataset_reas.xlsx')\n",
    "    \n",
    "    test_videos_df = pd.read_excel(f'../reas/train_dataset_{suffix}.xlsx')\n",
    "    \n",
    "    \n",
    "    # Rename 'test video' to 'video_name' in test dataset if needed\n",
    "    if 'test video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test video': 'video_name'}, inplace=True)\n",
    "    elif 'test_video' in test_videos_df.columns:\n",
    "        test_videos_df.rename(columns={'test_video': 'video_name'}, inplace=True)\n",
    "    \n",
    "    # Clean and parse rule embedding\n",
    "    rule_text_raw = rule_df['embedding'].iloc[0]\n",
    "    rule_text_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', rule_text_raw)\n",
    "    rule_embedding = np.array(eval(rule_text_clean))\n",
    "    \n",
    "    # Model list\n",
    "    model_list = ['claude-3-5-sonnet', 'flash', 'gpt-4o-mini', 'gpt4o', 'pro']\n",
    "    \n",
    "    # Training and test video names with .mp4 suffix\n",
    "    train_video_names = set(train_videos_df['video_name'].astype(str) + \".mp4\")\n",
    "    test_video_names = set(test_videos_df['video_name'].astype(str) + \".mp4\")\n",
    "    \n",
    "    # Store final results: video_name + 5 probabilities + average\n",
    "    prob_output = []\n",
    "    \n",
    "    # Initialize dict to store probabilities by model\n",
    "    prob_dict = {model: {} for model in model_list}\n",
    "    \n",
    "    # Loop over models\n",
    "    for model in model_list:\n",
    "        feature_list = []\n",
    "        y_list = []\n",
    "        video_name_list = []\n",
    "    \n",
    "        reas_emb_series = features_df[f\"{model}-reas_emb\"]\n",
    "        anomaly_series = features_df[f\"{model}-anomaly\"]\n",
    "        y_series = y_df[f\"{model}_y\"]\n",
    "        video_series = features_df['video_name']\n",
    "    \n",
    "        for emb_str, anom, label, vid in zip(reas_emb_series, anomaly_series, y_series, video_series):\n",
    "            if isinstance(emb_str, str):\n",
    "                emb_clean = re.sub(r'([0-9e\\.\\+\\-])\\s+([\\-0-9])', r'\\1, \\2', emb_str)\n",
    "                emb = np.array(eval(emb_clean))\n",
    "    \n",
    "                feature = np.concatenate([emb, [anom], rule_embedding])\n",
    "                feature_list.append(feature)\n",
    "                y_list.append(label)\n",
    "                video_name_list.append(vid)\n",
    "    \n",
    "        X = np.vstack(feature_list)\n",
    "        y = np.array(y_list)\n",
    "        video_names = np.array(video_name_list)\n",
    "    \n",
    "        # Split into train/test based on train/test datasets\n",
    "        train_idx = np.isin(video_names, list(train_video_names))\n",
    "        test_idx = np.isin(video_names, list(test_video_names))\n",
    "    \n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, video_test = X[test_idx], video_names[test_idx]\n",
    "    \n",
    "        model_lr = LogisticRegression(max_iter=1000)\n",
    "        model_lr.fit(X_train, y_train)\n",
    "    \n",
    "        # Predict probabilities on test set (probability of class 1)\n",
    "        probs = model_lr.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "        # Store probabilities by video name\n",
    "        for vid, prob in zip(video_test, probs):\n",
    "            prob_dict[model][vid] = prob\n",
    "    \n",
    "    # Collect all test video names (union from all models' outputs)\n",
    "    all_video_names = set()\n",
    "    for model_probs in prob_dict.values():\n",
    "        all_video_names.update(model_probs.keys())\n",
    "    \n",
    "    # Build final output\n",
    "    for vid in sorted(all_video_names):\n",
    "        row = {'video_name': vid}\n",
    "        prob_values = []\n",
    "        for model in model_list:\n",
    "            prob = prob_dict[model].get(vid, np.nan)\n",
    "            row[f\"{model}_prob\"] = prob\n",
    "            prob_values.append(prob)\n",
    "        row['average_prob'] = np.nanmean(prob_values)\n",
    "        prob_output.append(row)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_df = pd.DataFrame(prob_output)\n",
    "    output_df.to_excel(f\"model_prediction_probabilities_{suffix}_train.xlsx\", index=False)\n",
    "    \n",
    "    print(\"✅ Probability file saved as: model_prediction_probabilities.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343c65d-6063-4bb2-9449-257cf835d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    \n",
    "    prob_df = pd.read_excel(f'model_prediction_probabilities_{suffix}.xlsx')\n",
    "    \n",
    "    video_names = prob_df['video_name'].astype(str).values\n",
    "    uncertainty_scores = prob_df['average_prob']\n",
    "    \n",
    "    #uncertainty_scores = np.array(average_prob)  # Convert to NumPy array\n",
    "    \n",
    "    P_set = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    \n",
    "    for P in P_set:\n",
    "        tau = np.percentile(uncertainty_scores, 100 - P)\n",
    "        mask_low = uncertainty_scores <= tau\n",
    "        S_low_videos = video_names[mask_low]\n",
    "    \n",
    "        out_df = pd.DataFrame({\n",
    "            \"video_name\":  S_low_videos,\n",
    "            \"uncertainty\": uncertainty_scores[mask_low]\n",
    "        })\n",
    "        out_df.to_excel(f\"low list/S_low_videos_{P}_{suffix}_ref.xlsx\", index=False)\n",
    "        \n",
    "        print(f\"Threshold τ = {tau:.4f}\")\n",
    "        print(f\"Kept {len(S_low_videos)}/{len(video_names)} videos in S_low.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88557e-fde6-46e7-99ad-133aefa98e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "    \n",
    "    \n",
    "    prob_df = pd.read_excel(f'model_prediction_probabilities_{suffix}_train.xlsx')\n",
    "    \n",
    "    video_names = prob_df['video_name'].astype(str).values\n",
    "    uncertainty_scores = prob_df['average_prob']\n",
    "    \n",
    "    #uncertainty_scores = np.array(average_prob)  # Convert to NumPy array\n",
    "    \n",
    "    P_set = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    \n",
    "    for P in P_set:\n",
    "        tau = np.percentile(uncertainty_scores, 100 - P)\n",
    "        mask_low = uncertainty_scores <= tau\n",
    "        S_low_videos = video_names[mask_low]\n",
    "    \n",
    "        out_df = pd.DataFrame({\n",
    "            \"video_name\":  S_low_videos,\n",
    "            \"uncertainty\": uncertainty_scores[mask_low]\n",
    "        })\n",
    "        out_df.to_excel(f\"low list/S_low_videos_{P}_{suffix}_ref_train.xlsx\", index=False)\n",
    "        \n",
    "        print(f\"Threshold τ = {tau:.4f}\")\n",
    "        print(f\"Kept {len(S_low_videos)}/{len(video_names)} videos in S_low.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e6f61-3fa5-4adf-9e8d-9486bdc2394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model names\n",
    "model_names = [\"claude-3-5-sonnet\", \"flash\", \"gpt-4o-mini\", \"gpt4o\", \"pro\"]\n",
    "\n",
    "# P values representing percent of videos excluded as high-uncertainty\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Store results for each P\n",
    "    all_results = []\n",
    "    \n",
    "    for P in P_set:\n",
    "        \n",
    "        try:\n",
    "            low = pd.read_excel(f'low list/S_low_videos_{P}_{suffix}_ref.xlsx')\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load S_low_videos_{P}_trace.xlsx: {e}\")\n",
    "            continue\n",
    "        \n",
    "        low_list = low['video_name'].str.replace('.mp4', '', regex=False)\n",
    "        \n",
    "        # Store predictions per model\n",
    "        model_preds = {}\n",
    "        \n",
    "        for model in model_names:\n",
    "            try:\n",
    "                df = pd.read_csv(f'../../LLM_output_generation/vad_results_{model}.csv')\n",
    "                df['Video Name'] = df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "                df = df[df['Video Name'].isin(low_list)]\n",
    "                model_preds[model] = df[['Video Name', 'Predicted Label']].set_index('Video Name')\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Failed to process {model}: {e}\")\n",
    "        \n",
    "        # Merge all predictions\n",
    "        merged = pd.DataFrame(index=low_list)\n",
    "        for model in model_names:\n",
    "            merged[model] = model_preds.get(model, pd.DataFrame()).reindex(low_list)['Predicted Label']\n",
    "        \n",
    "        # Drop rows with missing predictions\n",
    "        merged = merged.dropna()\n",
    "        \n",
    "        if merged.empty:\n",
    "            print(f\"[Warning] No valid data for P={P}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Load ground truth from claude-3-5-sonnet\n",
    "        gt_df = pd.read_csv('../../LLM_output_generation/vad_results_claude-3-5-sonnet.csv')\n",
    "        gt_df['Video Name'] = gt_df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "        gt_df = gt_df[gt_df['Video Name'].isin(merged.index)]\n",
    "        ground_truth = gt_df.set_index('Video Name')['True Label']\n",
    "        \n",
    "        # Majority voting\n",
    "        majority_vote = merged.mode(axis=1)[0]\n",
    "        \n",
    "        # Align ground truth\n",
    "        y_true = ground_truth.loc[merged.index]\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, majority_vote)\n",
    "        prec = precision_score(y_true, majority_vote, zero_division=0)\n",
    "        rec = recall_score(y_true, majority_vote, zero_division=0)\n",
    "        f1 = f1_score(y_true, majority_vote, zero_division=0)\n",
    "        \n",
    "        all_results.append({\n",
    "            'P': P,\n",
    "            'Num Videos': len(merged),\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"[P={P}] Processed {len(merged)} videos | Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save final results to one Excel file\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_df.to_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref.xlsx', index=False)\n",
    "    print(\"[Saved] VAD_Majority_Voting_Summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e46123-ac51-42b3-bbe8-ee0277d2f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model names\n",
    "model_names = [\"claude-3-5-sonnet\", \"flash\", \"gpt-4o-mini\", \"gpt4o\", \"pro\"]\n",
    "\n",
    "# P values representing percent of videos excluded as high-uncertainty\n",
    "P_set = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Store results for each P\n",
    "    all_results = []\n",
    "    \n",
    "    for P in P_set:\n",
    "        \n",
    "        try:\n",
    "            low = pd.read_excel(f'low list/S_low_videos_{P}_{suffix}_ref_train.xlsx')\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load S_low_videos_{P}_trace.xlsx: {e}\")\n",
    "            continue\n",
    "        \n",
    "        low_list = low['video_name'].str.replace('.mp4', '', regex=False)\n",
    "        \n",
    "        # Store predictions per model\n",
    "        model_preds = {}\n",
    "        \n",
    "        for model in model_names:\n",
    "            try:\n",
    "                df = pd.read_csv(f'../../LLM_output_generation/vad_results_{model}.csv')\n",
    "                df['Video Name'] = df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "                df = df[df['Video Name'].isin(low_list)]\n",
    "                model_preds[model] = df[['Video Name', 'Predicted Label']].set_index('Video Name')\n",
    "            except Exception as e:\n",
    "                print(f\"[Error] Failed to process {model}: {e}\")\n",
    "        \n",
    "        # Merge all predictions\n",
    "        merged = pd.DataFrame(index=low_list)\n",
    "        for model in model_names:\n",
    "            merged[model] = model_preds.get(model, pd.DataFrame()).reindex(low_list)['Predicted Label']\n",
    "        \n",
    "        # Drop rows with missing predictions\n",
    "        merged = merged.dropna()\n",
    "        \n",
    "        if merged.empty:\n",
    "            print(f\"[Warning] No valid data for P={P}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Load ground truth from claude-3-5-sonnet\n",
    "        gt_df = pd.read_csv('../../LLM_output_generation/vad_results_claude-3-5-sonnet.csv')\n",
    "        gt_df['Video Name'] = gt_df['Video Name'].str.replace('.mp4', '', regex=False)\n",
    "        gt_df = gt_df[gt_df['Video Name'].isin(merged.index)]\n",
    "        ground_truth = gt_df.set_index('Video Name')['True Label']\n",
    "        \n",
    "        # Majority voting\n",
    "        majority_vote = merged.mode(axis=1)[0]\n",
    "        \n",
    "        # Align ground truth\n",
    "        y_true = ground_truth.loc[merged.index]\n",
    "        \n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_true, majority_vote)\n",
    "        prec = precision_score(y_true, majority_vote, zero_division=0)\n",
    "        rec = recall_score(y_true, majority_vote, zero_division=0)\n",
    "        f1 = f1_score(y_true, majority_vote, zero_division=0)\n",
    "        \n",
    "        all_results.append({\n",
    "            'P': P,\n",
    "            'Num Videos': len(merged),\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"[P={P}] Processed {len(merged)} videos | Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save final results to one Excel file\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_df.to_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref_train.xlsx', index=False)\n",
    "    print(\"[Saved] VAD_Majority_Voting_Summary.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525db0ed-7efc-4b90-a975-0a6debb4152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    suffix = f\"fold{fold}_reas\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Load the summary files\n",
    "    majority_df = pd.read_excel(f'low list/VAD_Majority_Voting_Summary_{suffix}_ref.xlsx')\n",
    "    \n",
    "    # Extract metrics\n",
    "    P_values = majority_df['P']\n",
    "    overall_accuracy = majority_df['Accuracy']\n",
    "    # recall = majority_df['Recall']\n",
    "    # vague_abnormal_accuracy = vague_df['Accuracy']\n",
    "    \n",
    "    # Combine into final DataFrame\n",
    "    out_df = pd.DataFrame({\n",
    "        'P': P_values,\n",
    "        'Overall Accuracy': overall_accuracy\n",
    "        # 'Recall': recall,\n",
    "        # 'Vague Abnormal Accuracy': vague_abnormal_accuracy\n",
    "    })\n",
    "    \n",
    "    # Remove final two rows\n",
    "    out_df = out_df.iloc[:, :]\n",
    "    \n",
    "    # Save to xlsx\n",
    "    out_df.to_excel(f'low list/results_P_{suffix}_ref.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
